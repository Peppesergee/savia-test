version: 2.1
model:
  checkpoints_folder: "/checkpoints/"
  model_name: "meta-llama/Llama-3.2-3B-Instruct"
quantization:
  load_in_4bit: False
  load_in_8bit: False
inference:
  do_sample: False
  num_beams: 1
  temperature:
  top_p: 
  max_new_tokens: 3000
  use_cache: True
device:
  device_name: "auto"
